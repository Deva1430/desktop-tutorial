{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ÈÄ£Êé•Ëá≥Èõ≤Á´ØÁ°¨Á¢ü\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM-yEae6JPc5",
        "outputId": "f1c5f885-91f9-4228-ef77-f9beea5e42ac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP8da4ibBAeP",
        "outputId": "5ad9d063-3243-47dc-83b2-318488981268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov9'...\n",
            "remote: Enumerating objects: 781, done.\u001b[K\n",
            "remote: Total 781 (delta 0), reused 0 (delta 0), pack-reused 781 (from 1)\u001b[K\n",
            "Receiving objects: 100% (781/781), 3.27 MiB | 7.31 MiB/s, done.\n",
            "Resolving deltas: 100% (331/331), done.\n"
          ]
        }
      ],
      "source": [
        "# Â∞áyolov9Ë≥áÊñôÂ§æ‰∏ãËºâËá≥Colab\n",
        "!git clone https://github.com/WongKinYiu/yolov9.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÈÄ≤ÂÖ•yolov9Ë≥áÊñôÂ§æ‰∏¶ÂÆâË£ùÁõ∏ÈóúÂ•ó‰ª∂\n",
        "%cd yolov9\n",
        "!pip install -r requirements.txt\n",
        "%cd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIf1IFrPBJXC",
        "outputId": "064d6780-98a4-4cd7-81e5-373b4e19a6b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov9\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.1.43)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (7.34.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (11.0.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (1.13.1)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 15))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (4.66.6)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (2.17.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: albumentations>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 46)) (1.4.20)\n",
            "Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 47)) (2.0.8)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython->-r requirements.txt (line 5)) (4.0.11)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 6)) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython->-r requirements.txt (line 6))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 6)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 6)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 6)) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 6)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 6)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 6)) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.7.0->-r requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (4.25.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.1.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations>=1.0.3->-r requirements.txt (line 46)) (2.10.3)\n",
            "Requirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.10/dist-packages (from albumentations>=1.0.3->-r requirements.txt (line 46)) (0.0.19)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations>=1.0.3->-r requirements.txt (line 46)) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations>=1.0.3->-r requirements.txt (line 46)) (4.10.0.84)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.19->albumentations>=1.0.3->-r requirements.txt (line 46)) (3.11.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython->-r requirements.txt (line 5)) (5.0.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 6)) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 6)) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations>=1.0.3->-r requirements.txt (line 46)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations>=1.0.3->-r requirements.txt (line 46)) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.0.2)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, thop\n",
            "Successfully installed jedi-0.19.2 thop-0.1.1.post2209072238\n",
            "/root\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ë§áË£ΩdatasetÊ™îÊ°àËá≥colab\n",
        "!rm -rf /content/data\n",
        "!mkdir /content/data\n",
        "!cp /content/drive/MyDrive/dataset.zip /content/data/dataset.zip"
      ],
      "metadata": {
        "id": "bRUrVm4-J07F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ëß£Â£ìÁ∏ÆÊ™îÊ°à\n",
        "!unzip /content/data/dataset.zip -d /content/data\n",
        "!rm -rf /content/data/dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsuZp8wxZ5_F",
        "outputId": "09c2d1ed-fe4a-450e-e443-b54db3ff6ccf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/data/dataset.zip\n",
            "   creating: /content/data/garbage/\n",
            "   creating: /content/data/garbage/images/\n",
            "   creating: /content/data/garbage/images/test/\n",
            "  inflating: /content/data/garbage/images/test/0.jpg  \n",
            "  inflating: /content/data/garbage/images/test/1947.jpg_wh860.jpg  \n",
            "  inflating: /content/data/garbage/images/test/20170624003915.jpg  \n",
            "  inflating: /content/data/garbage/images/test/20210531152803-70a6dde4.jpg  \n",
            "  inflating: /content/data/garbage/images/test/2998816.jpg  \n",
            "  inflating: /content/data/garbage/images/test/maxresdefault (1).jpg  \n",
            "  inflating: /content/data/garbage/images/test/maxresdefault.jpg  \n",
            "  inflating: /content/data/garbage/images/test/phpip9LVX.jpg  \n",
            "  inflating: /content/data/garbage/images/test/phpKdDoxE.jpg  \n",
            "   creating: /content/data/garbage/images/train/\n",
            "  inflating: /content/data/garbage/images/train/20230822144319-Lbz5gjBM.jpg  \n",
            "  inflating: /content/data/garbage/images/train/221230000073748025.jpg  \n",
            "  inflating: /content/data/garbage/images/train/37-1810-crystallized-for-hpr-600ml.jpg  \n",
            "  inflating: /content/data/garbage/images/train/EE2541803F-Product-21072335.jpg  \n",
            "  inflating: /content/data/garbage/images/train/photo.jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (1).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (10).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (11).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (12).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (13).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (14).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (15).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (16).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (17).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (18).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (19).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (2).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (20).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (21).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (22).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (23).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (24).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (25).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (26).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (27).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (28).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (29).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (3).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (30).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (31).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (32).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (33).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (34).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (35).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (36).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (37).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (38).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (39).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (4).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (40).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (41).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (42).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (43).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (44).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (45).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (46).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (47).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (48).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (49).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (5).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (50).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (51).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (52).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (53).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (54).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (55).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (56).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (57).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (58).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (59).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (6).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (60).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (61).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (62).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (63).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (64).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (65).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (66).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (67).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (68).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (69).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (7).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (70).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (71).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (72).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (73).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (74).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (75).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (76).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (77).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (78).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (79).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (8).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (80).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (81).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (82).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th (9).jpg  \n",
            "  inflating: /content/data/garbage/images/train/th.jpg  \n",
            "  inflating: /content/data/garbage/images/train/tw-11134207-7quky-li8hbetgrq9g2a.jpg  \n",
            "   creating: /content/data/garbage/images/val/\n",
            "  inflating: /content/data/garbage/images/val/1693149790_31930.jpg  \n",
            "  inflating: /content/data/garbage/images/val/173018875137018_P11172252.jpg  \n",
            "  inflating: /content/data/garbage/images/val/52a273c7ff7f4429b430503c11f0412b.jpg  \n",
            "  inflating: /content/data/garbage/images/val/cGcq5SMwgTZ3cTOhRGOzczMwUmZ4AjNkRmM3UmM4EGO3ETZxMmZmNmNyMDOv0WZ0l2LjlGcvU2apFmYv02bj5SdklWYi5yYyN3Ztl2LvoDc0RHa.jpg  \n",
            "  inflating: /content/data/garbage/images/val/d3323106.jpg  \n",
            "  inflating: /content/data/garbage/images/val/DSC00581.JPG  \n",
            "  inflating: /content/data/garbage/images/val/e4165093.jpg  \n",
            "  inflating: /content/data/garbage/images/val/maxresdefault.jpg  \n",
            "  inflating: /content/data/garbage/images/val/original.jpg  \n",
            "   creating: /content/data/garbage/labels/\n",
            "   creating: /content/data/garbage/labels/test/\n",
            "   creating: /content/data/garbage/labels/train/\n",
            "  inflating: /content/data/garbage/labels/train/20230822144319-Lbz5gjBM.txt  \n",
            "  inflating: /content/data/garbage/labels/train/221230000073748025.txt  \n",
            "  inflating: /content/data/garbage/labels/train/37-1810-crystallized-for-hpr-600ml.txt  \n",
            "  inflating: /content/data/garbage/labels/train/classes.txt  \n",
            "  inflating: /content/data/garbage/labels/train/EE2541803F-Product-21072335.txt  \n",
            "  inflating: /content/data/garbage/labels/train/photo.txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (1).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (10).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (11).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (12).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (13).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (14).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (15).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (16).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (17).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (18).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (19).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (2).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (20).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (21).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (22).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (23).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (24).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (25).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (26).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (27).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (28).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (29).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (3).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (30).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (31).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (32).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (33).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (34).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (35).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (36).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (37).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (38).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (39).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (4).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (40).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (41).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (42).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (44).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (45).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (46).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (47).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (48).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (49).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (5).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (50).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (51).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (52).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (53).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (54).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (55).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (56).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (57).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (58).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (59).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (6).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (60).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (61).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (62).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (63).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (64).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (65).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (66).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (67).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (68).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (69).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (7).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (70).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (71).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (72).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (73).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (74).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (75).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (76).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (77).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (78).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (79).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (8).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (80).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (81).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (82).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th (9).txt  \n",
            "  inflating: /content/data/garbage/labels/train/th.txt  \n",
            "  inflating: /content/data/garbage/labels/train/tw-11134207-7quky-li8hbetgrq9g2a.txt  \n",
            "   creating: /content/data/garbage/labels/val/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Ë¶ÅÁßªÂãïÁöÑÁõÆÈåÑË∑ØÂæë\n",
        "source_dir = '/content/data/datasets'\n",
        "# ÁõÆÊ®ô‰ΩçÁΩÆÁöÑÁõÆÈåÑË∑ØÂæë\n",
        "target_dir = '/content/yolov9/data'\n",
        "\n",
        "shutil.move(source_dir, target_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "neY-k7sYaLPr",
        "outputId": "2ce39e5e-187e-4c8d-d9f0-39c18bec07ce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/yolov9/data/datasets'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‰∏ãËºâÈ†êË®ìÁ∑¥Ê¨äÈáç\n",
        "!mkdir /content/yolov9/weight\n",
        "!wget -O /content/yolov9/weight/yolov9-c.pt https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhKnTTdWbMOI",
        "outputId": "5a9dff85-5d26-400c-c988-4aba1fdd02c0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-09 17:58:46--  https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/759338070/c8ca43f2-0d2d-4aa3-a074-426505bfbfb1?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241209%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241209T175847Z&X-Amz-Expires=300&X-Amz-Signature=17835ab5c8a575fc073057ea5e6286609c1828b57dd757bf5cf01d6875a20e2e&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov9-c.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-12-09 17:58:47--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/759338070/c8ca43f2-0d2d-4aa3-a074-426505bfbfb1?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241209%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241209T175847Z&X-Amz-Expires=300&X-Amz-Signature=17835ab5c8a575fc073057ea5e6286609c1828b57dd757bf5cf01d6875a20e2e&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov9-c.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 103153312 (98M) [application/octet-stream]\n",
            "Saving to: ‚Äò/content/yolov9/weight/yolov9-c.pt‚Äô\n",
            "\n",
            "/content/yolov9/wei 100%[===================>]  98.37M   117MB/s    in 0.8s    \n",
            "\n",
            "2024-12-09 17:58:48 (117 MB/s) - ‚Äò/content/yolov9/weight/yolov9-c.pt‚Äô saved [103153312/103153312]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train yolov9 models\n",
        "%cd /content/yolov9\n",
        "\n",
        "!python train_dual.py \\\n",
        "--batch 4 --epochs 20 --img 640 --device 0 --min-items 0 --close-mosaic 15 \\\n",
        "--data /content/yolov9/data/datasets.yaml \\\n",
        "--weights /content/yolov9/weight/yolov9-c.pt \\\n",
        "--cfg models/detect/yolov9-c.yaml \\\n",
        "--hyp hyp.scratch-high.yaml"
      ],
      "metadata": {
        "id": "eucgdvvgIA7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d055998-f145-424f-c27b-47b1905dd5db"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov9\n",
            "2024-12-09 18:02:07.887011: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-09 18:02:07.906917: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-09 18:02:07.913199: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-09 18:02:07.927513: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-09 18:02:09.131663: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=/content/yolov9/weight/yolov9-c.pt, cfg=models/detect/yolov9-c.yaml, data=/content/yolov9/data/datasets.yaml, hyp=hyp.scratch-high.yaml, epochs=20, batch_size=4, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=15, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "YOLO üöÄ v0.1-104-g5b1ea9a Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO üöÄ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO üöÄ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m0966199115matt\u001b[0m (\u001b[33m0966199115matt-student\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/yolov9/wandb/run-20241209_180240-sawcgou2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mworldly-sea-4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/0966199115matt-student/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/0966199115matt-student/YOLOv5/runs/sawcgou2\u001b[0m\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 26.2MB/s]\n",
            "/content/yolov9/train_dual.py:110: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(weights, map_location='cpu')  # load checkpoint to CPU to avoid CUDA memory leak\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1         0  models.common.Silence                   []                            \n",
            "  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
            "  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  3                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n",
            "  4                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
            "  5                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n",
            "  6                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            "  7                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            "  8                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            "  9                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            " 10                -1  1    656896  models.common.SPPELAN                   [512, 512, 256]               \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 7]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
            " 14                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 15           [-1, 5]  1         0  models.common.Concat                    [1]                           \n",
            " 16                -1  1    912640  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 1]      \n",
            " 17                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
            " 18          [-1, 13]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   2988544  models.common.RepNCSPELAN4              [768, 512, 512, 256, 1]       \n",
            " 20                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            " 21          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 22                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
            " 23                 5  1    131328  models.common.CBLinear                  [512, [256]]                  \n",
            " 24                 7  1    393984  models.common.CBLinear                  [512, [256, 512]]             \n",
            " 25                 9  1    656640  models.common.CBLinear                  [512, [256, 512, 512]]        \n",
            " 26                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
            " 27                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            " 28                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n",
            " 29                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
            " 30  [23, 24, 25, -1]  1         0  models.common.CBFuse                    [[0, 0, 0]]                   \n",
            " 31                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n",
            " 32                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            " 33      [24, 25, -1]  1         0  models.common.CBFuse                    [[1, 1]]                      \n",
            " 34                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            " 35                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            " 36          [25, -1]  1         0  models.common.CBFuse                    [[2]]                         \n",
            " 37                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            " 38[31, 34, 37, 16, 19, 22]  1  21542822  models.yolo.DualDDetect                 [1, [512, 512, 512, 256, 512, 512]]\n",
            "yolov9-c summary: 962 layers, 50999590 parameters, 50999558 gradients, 238.9 GFLOPs\n",
            "\n",
            "Transferred 1448/1460 items from /content/yolov9/weight/yolov9-c.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 238 weight(decay=0.0), 255 weight(decay=0.0005), 253 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov9/data/datasets/labels/train... 88 images, 1 backgrounds, 0 corrupt: 100% 89/89 [00:00<00:00, 707.20it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov9/data/datasets/labels/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov9/data/datasets/labels/val... 0 images, 9 backgrounds, 0 corrupt: 100% 9/9 [00:00<00:00, 453.74it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è No labels found in /content/yolov9/data/datasets/labels/val.cache. See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov9/data/datasets/labels/val.cache\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "/content/yolov9/train_dual.py:255: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0% 0/23 [00:00<?, ?it/s]/content/yolov9/train_dual.py:313: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       0/19      4.95G      1.363       2.52      1.773         17        640:   0% 0/23 [00:04<?, ?it/s]Exception in thread Thread-13 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 300, in plot_images\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "WARNING ‚ö†Ô∏è TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n",
            "       0/19      4.95G      1.363       2.52      1.773         17        640:   4% 1/23 [00:08<03:15,  8.86s/it]/content/yolov9/train_dual.py:313: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       0/19      5.09G      1.215      2.514      1.647         25        640:   9% 2/23 [00:09<01:23,  3.95s/it]Exception in thread Thread-14 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 300, in plot_images\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "       0/19      5.09G      1.277      2.781       1.65         11        640:  13% 3/23 [00:09<00:47,  2.38s/it]Exception in thread Thread-15 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 300, in plot_images\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "       0/19      5.57G      1.489      3.034      1.855          2        640: 100% 23/23 [00:18<00:00,  1.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  2.00it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/19      6.22G      1.448       2.03      1.836          8        640: 100% 23/23 [00:10<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:02<00:00,  1.00s/it]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/19      6.22G       1.38      1.553      1.669         10        640: 100% 23/23 [00:10<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.96it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/19      6.22G      1.309      1.551      1.674          5        640: 100% 23/23 [00:10<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.24it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/19      6.22G      1.377      1.668      1.741          3        640: 100% 23/23 [00:10<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.60it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/19      6.22G      1.453      2.529      1.882          4        640: 100% 23/23 [00:10<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.11it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/19      6.22G       1.45      2.316      1.831          2        640: 100% 23/23 [00:10<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.59it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/19      6.22G      1.603      2.433      1.899          1        640: 100% 23/23 [00:10<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.37it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/19      6.22G      1.435      1.863      1.799          1        640: 100% 23/23 [00:11<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.40it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/19      6.22G      1.461      1.795      1.784          3        640: 100% 23/23 [00:10<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.37it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/19      6.22G      1.426      1.708      1.712          1        640: 100% 23/23 [00:10<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.13it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/19      6.22G      1.363      1.676      1.754          1        640: 100% 23/23 [00:10<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.05it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/19      6.22G      1.462      1.553      1.813          1        640: 100% 23/23 [00:10<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.74it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/19      6.22G      1.495      1.739      1.812          1        640: 100% 23/23 [00:10<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.06it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/19      6.22G      1.356      1.559      1.721          4        640: 100% 23/23 [00:10<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.54it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/19      6.22G      1.399      1.399      1.831          2        640: 100% 23/23 [00:10<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.09it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/19      6.22G      1.275      1.406      1.717          1        640: 100% 23/23 [00:11<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.25it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/19      6.22G       1.24      1.213      1.679          3        640: 100% 23/23 [00:10<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.24it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/19      6.22G      1.421      1.333      1.787          1        640: 100% 23/23 [00:10<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.79it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/19      6.22G      1.266      1.267      1.714          1        640: 100% 23/23 [00:10<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.08it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "\n",
            "20 epochs completed in 0.097 hours.\n",
            "/content/yolov9/utils/general.py:999: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  x = torch.load(f, map_location=torch.device('cpu'))\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 102.8MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 102.8MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "/content/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "yolov9-c summary: 604 layers, 50698278 parameters, 0 gradients, 236.6 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50% 1/2 [00:01<00:01,  1.21s/it]Exception in thread Thread-36 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 300, in plot_images\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.29it/s]\n",
            "                   all          9          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\n",
            "Exception in thread Thread-38 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 300, in plot_images\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 61.191 MB of 132.411 MB uploaded\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 132.411 MB of 132.411 MB uploaded\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 132.411 MB of 132.411 MB uploaded\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 132.411 MB of 132.411 MB uploaded\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 132.411 MB of 132.411 MB uploaded\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/dfl_loss ‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÇ‚ñÅ‚ñÖ‚ñÇ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/dfl_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 19\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 1.26579\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 1.26725\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/dfl_loss 1.71366\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/dfl_loss 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00109\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00109\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00109\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mworldly-sea-4\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/0966199115matt-student/YOLOv5/runs/sawcgou2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/0966199115matt-student/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 4 artifact file(s) and 186 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241209_180240-sawcgou2/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ê∏¨Ë©¶\n",
        "%cd /content/yolov9\n",
        "\n",
        "!python detect_dual.py --weights /content/yolov9/runs/train/exp/weights/best.pt\\\n",
        "--conf 0.75\\\n",
        "--source /content/yolov9/data/datasets/images/test/20170624003915.jpg\\\n",
        "--device 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s4UjAboe719",
        "outputId": "7db5db83-d6f8-47e2-d111-9901a11df197"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov9\n",
            "\u001b[34m\u001b[1mdetect_dual: \u001b[0mweights=['/content/yolov9/runs/train/exp/weights/best.pt'], source=/content/yolov9/data/datasets/images/test/20170624003915.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.75, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO üöÄ v0.1-104-g5b1ea9a Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "/content/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "yolov9-c summary: 604 layers, 50698278 parameters, 0 gradients, 236.6 GFLOPs\n",
            "image 1/1 /content/yolov9/data/datasets/images/test/20170624003915.jpg: 384x640 (no detections), 71.2ms\n",
            "Speed: 0.4ms pre-process, 71.2ms inference, 21.5ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vZLJo0xGf4nB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}